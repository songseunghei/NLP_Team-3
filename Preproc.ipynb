{"cells":[{"cell_type":"markdown","id":"lx5s0lWALq9_","metadata":{"id":"lx5s0lWALq9_"},"source":["연습 문제 들어가기 전에, 코드가 올바른 폴더에 위치해 있는지 점검해보자.\n","\n","**NLP 중간 미션 파일 전체는 반드시 개인 구글 드라이브 내 NLP 폴더에 위치해 있어야 한다.**\n","\n","뒤에 ratings.txt를 읽어오는데 어려움을 겪고 있다면, 파일들이 올바른 위치에 있는지 다시 한 번 점검해보자."]},{"cell_type":"markdown","id":"wNqoPN9nsdKt","metadata":{"id":"wNqoPN9nsdKt"},"source":["# **Preproc.ipynb**\n","\n","우리는 문장을 입력해주었을 때, 그 문장이 긍정문인지 부정문인지 판단해주는 AI 모델을 구축하고자 한다. AI 모델이 문장을 올바르게 분류하기 위해서는 문장 내 정보들을 인지하는 과정이 필요하다.\n","\n","컴퓨터는 우리가 사용하는 언어를 있는 그대로 받아들일 수 없다. 컴퓨터가 이해할 수 있는 방식, 숫자로 변환해주어야 한다. 이와 같이 AI 모델이 주어진 데이터를 이해할 수 있도록, 데이터의 형태를 변환해주는 과정을 전처리 (Preprocessing) 라고 한다.\n","\n","**본 파일에서는 문장 데이터를 전처리하는 과정에 대해 다뤄볼 것이다.**\n","\n","전처리에 필요한 함수들을 구성한 뒤, 최하단의 preproc_test 함수를 통해서 테스트해볼 것이다."]},{"cell_type":"markdown","id":"_t5wa4UAuk96","metadata":{"id":"_t5wa4UAuk96"},"source":["연습 문제를 시작하기에 앞서, 필요한 라이브러리들을 설치하자."]},{"cell_type":"code","execution_count":1,"id":"b7d3c81d","metadata":{"id":"b7d3c81d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660271816382,"user_tz":-540,"elapsed":38132,"user":{"displayName":"승희송승","userId":"13532987981801919518"}},"outputId":"86ec870d-22ab-4169-c70f-f760b6f698e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 62.5 MB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 12.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595741 sha256=8e6c7049a187fc461e2a5900f60b56ea78c960311ac6af9686f4e394067dadfd\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 33.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 29.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 64.1 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.97)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=30489eee88ce1dcec67d9bf013575a3b7a2c35adfd33028851e06c167ba8e6e0\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","\u001b[K     |████████████████████████████████| 6.3 MB 27.0 MB/s \n","\u001b[?25h"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch\n","!pip install --upgrade -q pyproj"]},{"cell_type":"markdown","id":"ua7HcCVDvuMs","metadata":{"id":"ua7HcCVDvuMs"},"source":["아래의 mount 함수를 통해 구글 드라이브에 접근하자."]},{"cell_type":"code","execution_count":2,"id":"pdM0BfJEVz1k","metadata":{"id":"pdM0BfJEVz1k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660271839942,"user_tz":-540,"elapsed":19407,"user":{"displayName":"승희송승","userId":"13532987981801919518"}},"outputId":"3c83058b-e2e8-4d41-9bfb-22f56cc32cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","id":"23jcqTeGwzgk","metadata":{"id":"23jcqTeGwzgk"},"source":["연습 문제에 필요한 라이브러리들을 import하자."]},{"cell_type":"code","execution_count":3,"id":"74f1716b","metadata":{"id":"74f1716b","executionInfo":{"status":"ok","timestamp":1660271850388,"user_tz":-540,"elapsed":8359,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","import traceback\n","import pickle\n"]},{"cell_type":"markdown","id":"I2Bzrqxxxo7a","metadata":{"id":"I2Bzrqxxxo7a"},"source":["Pandas 라이브러리의 read_csv 함수를 활용하여 데이터셋을 읽어오자."]},{"cell_type":"code","execution_count":4,"id":"s58zYf3TdJiJ","metadata":{"id":"s58zYf3TdJiJ","executionInfo":{"status":"ok","timestamp":1660271864115,"user_tz":-540,"elapsed":1152,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["whole_dataset = pd.read_csv('/content/gdrive/MyDrive/NLP/ratings.txt', delimiter=\"\\t\")    "]},{"cell_type":"markdown","id":"BgRtfBYvxzLY","metadata":{"id":"BgRtfBYvxzLY"},"source":["읽어 온 데이터의 형태는 어떠할까?\n","\n","head 함수를 활용하여 상단 5개의 data들을 출력해보고, data의 row와 column은 어떻게 구성되어 있는지 살펴보자."]},{"cell_type":"code","execution_count":5,"id":"Y1bOaRtrZ1D9","metadata":{"id":"Y1bOaRtrZ1D9","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1660271869757,"user_tz":-540,"elapsed":294,"user":{"displayName":"승희송승","userId":"13532987981801919518"}},"outputId":"9d663dc9-6122-4282-c456-3bd4087656b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n","2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n","3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n","4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"],"text/html":["\n","  <div id=\"df-59314cff-6798-480e-8789-f6531614b5b0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59314cff-6798-480e-8789-f6531614b5b0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-59314cff-6798-480e-8789-f6531614b5b0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-59314cff-6798-480e-8789-f6531614b5b0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["whole_dataset.head()"]},{"cell_type":"markdown","id":"EjMmau3TyPHo","metadata":{"id":"EjMmau3TyPHo"},"source":["데이터를 살펴보니, row는 0부터 차례로 이어지며, column은 id, document, label로 구성되어 있다.\n","\n","id는 데이터를 구분짓기 위한 일련 번호, document는 문장 데이터, label은 해당하는 문장이 긍정(1), 부정(0)인지 나타내는 라벨 값이다.\n","\n","여기서 우리는 학습 데이터들 간에 구분할 필요가 없으므로, id 데이터는 분리하자. 그리고 column 이름으로 document보다는 sentence가 적절해보이니, 그렇게 바꿔보자."]},{"cell_type":"code","execution_count":6,"id":"57f17468","metadata":{"id":"57f17468","executionInfo":{"status":"ok","timestamp":1660271877077,"user_tz":-540,"elapsed":355,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def data_processing(raw_data):    \n","    transformed_data = raw_data['label']\n","    \n","    # 판다스의 concat을 활용하여 'document' 데이터와 'label' 데이터를 연결해보자.\n","    # [1] new_array = pandas.concat([array1, array2])를 하면, array1과 array2가 물리적으로 연결된 new_array를 생성할 수 있다. \n","    #     이때 추가 옵션을 별도로 지정하지 않았으므로, concat을 수행하는 default 방향은 axis=0(default)이다.\n","    # [2] concat 시 axis 조건을 통해 array를 concat하는 방향을 직접 지정해주도록 하자.\n","    #     Hint: 2차원 array에서 axis=0은 세로(상/하) 방향, axis=1은 가로(좌/우) 방향이다.\n","    #     우리는 'document'열과 'label' 열을 가로(좌/우) 방향으로 concat해야 하므로 concat 시 axis=1이라는 조건을 설정하는 것이 적합할 것이다.\n","    # concat에 대한 추가적인 내용은 https://yganalyst.github.io/data_handling/Pd_12/ 를 참고해보자.\n","    # axis에 대한 추가적인 내용은 https://jalammar.github.io/visual-numpy/ https://lets-hci-la-ai-withme.tistory.com/15 를 참고해보자.\n","    ## 여기에 코드 작성\n","    df1 = raw_data['document']\n","    df2 = raw_data['label']\n","    processed_data = pd.concat([df1, df2], axis=1)\n","\n","\n","    # 데이터의 column 이름을 sentence label로 바꾸어준다.\n","    processed_data.columns = ['sentence', 'label']\n","\n","    return processed_data"]},{"cell_type":"markdown","id":"wKH9R1WuEnck","metadata":{"id":"wKH9R1WuEnck"},"source":["여기까지 구현한 부분을 하단의 preproc_test 함수의 첫 번째 테스트로 확인해볼 것이다. (20점)"]},{"cell_type":"markdown","id":"ZNO2Hi2Q4dpb","metadata":{"id":"ZNO2Hi2Q4dpb"},"source":["이제 문장 데이터를 본격적으로 변환시켜볼 것이다.\n","\n","아래 data_to_token_ids 함수를 아래와 같은 절차를 통해 문장 데이터를 수치적으로 변환한다.\n","\n","1. Tokenizer가 문장의 시작과 끝을 인식할 수 있도록 문장 앞뒤에 CLS 토큰과 SEP 토큰을 붙인다.\n","\n","2. Tokenizer의 tokenize 함수를 활용하여 문장을 여러 개의 토큰으로 나눈다.\n","\n","3. Tokenizer의 convert_tokens_to_ids 함수를 활용하여, 토큰들을 대응되는 id로 변환해준다.\n","\n","4. MAX_LEN의 길이에 맞춰, padding을 진행해준다. 비어있는 자리의 경우, 0이 입력된다."]},{"cell_type":"code","execution_count":7,"id":"71055cfe","metadata":{"id":"71055cfe","executionInfo":{"status":"ok","timestamp":1660271894548,"user_tz":-540,"elapsed":291,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def data_to_token_ids(tokenizer, single_sentence):\n","    # CLS 토큰과 SEP 토큰을 문장의 시작과 끝에 붙여보자.\n","    ## 여기에 코드 작성\n","    modified_sentence = '[CLS]' + str(single_sentence) + '[SEP]'\n","    # tokenizer의 tokenize 함수를 활용하여 문장을 토큰화해보자.\n","    tokenized_sentence = tokenizer.tokenize(modified_sentence)\n","\n","    # tokenizer의 convert_tokens_to_ids 함수를 활용하여 생성된 토큰을 숫자 형태로 바꿔주자.\n","    token_ids = [tokenizer.convert_tokens_to_ids(tokenized_sentence)]\n","\n","    MAX_LEN = 128\n","    # pad_sequences 함수를 활용하여 문장의 빈 칸에 padding을 넣어주자.\n","    # keras의 preprocessing.sequence 라이브러리는 pad_sequences 함수를 제공하며, 본 함수는 서로 다른 길이의 문장을 특정 길이(최대 길이)로 일치시키기 위해 truncating와 padding을 한다.\n","    # truncating은 최대 길이보다 긴 문장을 최대 길이에 맞게 잘라내는 것이고, padding은 최대 길이보다 짧은 문장의 남는 자리를 0으로 채우는 것을 가리킨다.\n","    # pad_sequence는 default 옵션은 'pre'이다. 즉 긴 문장의 앞 부분을 잘라내거나 짧은 문장의 앞에 0을 채운다.\n","    # 그러나 우리는 토큰 id 리스트의 '뒷'부분에 truncating 및 padding을 적용해주고자 한다.\n","    # truncating=\"post\" 옵션을 통해 id 리스트의 길이가 MAX_LEN을 넘어가는 부분에 대해서는 뒷부분을 삭제할 수 있다.\n","    # padding=\"post\" 옵션을 통해 토큰 id 리스트의 뒷부분에 padding을 적용할 수 있다. \n","    # 최대 길이는 위의 MAX_LEN으로 설정하고, dtype은 long으로 설정해주자.\n","    # 위 설정에 맞게 padding, truncating 값을 적절히 설정해주자.\n","    # https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n","    ## 여기에 코드 작성\n","    token_ids_padded = pad_sequences(token_ids, maxlen=MAX_LEN,dtype=\"long\", padding=\"post\", \n","                                     truncating=\"post\")\n","\n","    token_ids_flatten = token_ids_padded.flatten()\n","    return token_ids_flatten"]},{"cell_type":"markdown","id":"f_37Yb-NqxgA","metadata":{"id":"f_37Yb-NqxgA"},"source":["완성한 data_to_token_ids 함수를 간단히 활용해보며 함수의 반환값 형태를 익혀보자.  \n","문장이 토큰화되고 각 토큰이 id값으로 반환되었으며, 최대 길이에 미치지 못하는 부분은 문장의 뒷부분에 0으로 padding 처리가 되었음을 확인할 수 있다.  \n","\n","\n","\n","```\n","from tokenization import KoBertTokenizer\n","tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","id_testing = data_to_token_ids(tokenizer, \"찐배고픔이랑 가짜배고픔이랑 구분하는건 이미포기했어\")\n","\n","print(id_testing)\n","\n","# [   2  517 7385 6312 5439 7766 7096 6022  770 6312 5439 7766 7096 6022\n"," 1115 6416 7794 5384 3692 7728 5561 7864 6855    3    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","\n","```\n","\n","위와 같은 방식으로 tokenizer와 임의의 한국어 문장을 입력하여, 함수가 정확히 만들어졌는지 확인해보도록 하자.\n"]},{"cell_type":"markdown","id":"h9yYk0CI87Td","metadata":{"id":"h9yYk0CI87Td"},"source":["pad_sequences 함수를 통해 padding이 이루어진 부분은 학습하는데 실질적으로 쓰이지 않는다.\n","\n","그러므로, padding된 부분은 고려하지 않도록 필터링해주는 mask를 만들어보자.\n","\n","여기서 mask는 padding된 부분은 지우고, 나머지 부분은 그대로 두는 기능을 한다. 고로, padding된 부분은 0, 아닌 부분은 1의 값을 나타내도록 한다."]},{"cell_type":"code","execution_count":8,"id":"0ec337a5","metadata":{"id":"0ec337a5","executionInfo":{"status":"ok","timestamp":1660271899071,"user_tz":-540,"elapsed":312,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def token_ids_to_mask(token_ids):\n","    \n","    # 한 문장에 대한 token_id 리스트를 입력으로 받는다.\n","    # token_id에서 0보다 큰 숫자만 유효하도록 하는 'mask' 리스트를 만들자.\n","    # 이 때, mask의 각 원소는 0 아니면 1의 값을 가져야 한다.\n","    # Hint : 각 token_id를 0 아니면 1의 값으로 바꿔주면 된다.\n","    # Hint : list comprehension을 활용해서 작성하면 편하다.\n","    ## 여기에 코드 작성\n","    mask = []\n","    for i in token_ids:\n","      if i>0:\n","        i = 1\n","      if i ==0:\n","        i=0\n","      mask.append(i)\n","\n","    return mask\n"]},{"cell_type":"markdown","id":"V-bizxlEq6ab","metadata":{"id":"V-bizxlEq6ab"},"source":["마찬가지로, 완성한 token_ids_to_mask 함수를 간단히 활용해보며 함수의 반환값 형태를 익혀보자.  \n","0으로 패딩처리된 부분은 0.0으로, 나머지는 1.0으로 채워진 max_length 길이의 array가 반환됨을 확인할 수 있다.\n","\n","```\n","mask_testing = token_ids_to_mask(id_testing)\n","print(mask_testing)\n","\n","# [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","```\n","\n","위와 같은 방식으로, 앞서 생성한 id_testing을 입력하여 함수가 정확히 만들어졌는지 확인해보도록 하자.\n"]},{"cell_type":"markdown","id":"EsMqQ9qI-Mad","metadata":{"id":"EsMqQ9qI-Mad"},"source":["data_to_token_ids 함수는 하나의 문장이 입력되었을 때, token_id 리스트를 출력해주는 함수이며, token_ids_to_mask 함수는 한 문장에 대한 token_id 리스트가 입력되었을 때, 하나의 mask를 생성해주는 함수다.\n","위에서 구성한 두 가지 함수를 활용해서, 전체 데이터를 변형하는 로직을 구성해보자.\n","\n","*HINT : list comprehension을 활용하는 것이 가장 간결한 코드이며, 조금 어렵다면 for 문을 활용해봐도 좋다.*"]},{"cell_type":"code","execution_count":9,"id":"c0509ac6","metadata":{"id":"c0509ac6","executionInfo":{"status":"ok","timestamp":1660271906071,"user_tz":-540,"elapsed":296,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["# tokenize_processed_data 함수는, 앞서 정의한 함수인 data_to_token_ids와 token_ids_to_mask를 모두 활용한다.\n","# tokenize_processed_data 함수를 통해, 데이터를 구성하는 각 문장을 '토큰 id로 구성된, max_length 길이의 array'로 변환해주고, attention 마스크를 생성하는 작업을 한꺼번에 처리할 수 있다.\n","# 함수의 입력은 두 가지로, [1]tokenizer, [2] raw_data를 data_processing 함수로 전처리한 결과인 processed_dataset이다.\n","# 함수의 출력은 세 가지로, [1]tokenized_data (='토큰 id로 구성된 max_length 길이의 array'로 구성된 list), [2] 데이터의 labels, [3] 각 array에 대응하는 attention_masks로 구성된 list이다.\n","\n","def tokenize_processed_data(tokenizer, processed_dataset):\n","    labels = processed_dataset['label'].to_numpy()\n","    \n","    # list comprehension을 활용하여 processed_dataset의 'sentence' 데이터를 id 리스트로 토큰화하자.\n","    ## 여기에 코드 작성\n","    tokenized_data=[data_to_token_ids(tokenizer,n) for n in processed_dataset['sentence']]\n","\n","    # list comprehension을 활용하여 앞서 토큰화한 id 리스트 각각을 mask로 변환하자.\n","    ## 여기에 코드 작성\n","    attention_masks=[token_ids_to_mask(token) for token in tokenized_data] \n","    return tokenized_data, labels, attention_masks"]},{"cell_type":"markdown","id":"2QPPr-B7EBFI","metadata":{"id":"2QPPr-B7EBFI"},"source":["여기까지 구현한 부분을 하단의 preproc_test 함수의 두 번째 테스트로 확인해볼 것이다. (40점)"]},{"cell_type":"markdown","id":"50qJbROTAD2n","metadata":{"id":"50qJbROTAD2n"},"source":["위의 함수를 통해 변환한 데이터셋을 train, validation, test용으로 나눠야 한다.\n","\n","split_into_train_test 함수를 통해 train 데이터와 test 데이터로 나누고, 그렇게 나누어진 train 데이터를 split_into_train_validation 함수를 통해 train 데이터와 validation 데이터로 나눌 것이다.\n","\n","sklearn.model_selection 라이브러리의 train_test_split 함수를 활용하여 아래의 두 함수를 구현해보자."]},{"cell_type":"code","execution_count":10,"id":"HW7i_vdmSXIn","metadata":{"id":"HW7i_vdmSXIn","executionInfo":{"status":"ok","timestamp":1660271910672,"user_tz":-540,"elapsed":374,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def split_into_train_test(whole_data, whole_label, whole_masks):\n","    print(\"length of whole_data : \" + str(len(whole_data)))\n","\n","    train_inputs, test_inputs, train_labels, test_labels = train_test_split(whole_data,\n","                                                                                    whole_label,\n","                                                                                    random_state=2022, \n","                                                                                    test_size=0.1)\n","    # 위의 방식을 참조하여 mask 역시 train을 위한 mask와 test을 위한 mask로 나누자.\n","    # 이때 return 값을 참조하여, 우리에게 불필요한 정보는 _로 비워두자.\n","    # random_state와 test_size 동일하게 설정\n","    ## 여기에 코드 작성\n","    train_masks, test_masks, _, _ = train_test_split(whole_masks, whole_label, random_state=2022, test_size=0.1)\n","    return train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks"]},{"cell_type":"code","execution_count":11,"id":"t2ymZef0SrK-","metadata":{"id":"t2ymZef0SrK-","executionInfo":{"status":"ok","timestamp":1660271919000,"user_tz":-540,"elapsed":282,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def split_into_train_validation(train_data, train_label, train_masks):\n","    print(\"length of train_data : \" + str(len(train_data)))\n","    \n","    # split_into_train_test의 코드를 참조하여 data와 mask 각각을 train을 위한 것과 validation을 위한 것으로 나누자.\n","    # random_state = 2022, test_size = 0.1로 설정\n","    \n","    ## 여기에 코드 작성(data)\n","    train_inputs, validation_inputs, train_labels, validation_labels=train_test_split(train_data,\n","                                                                                      train_label,\n","                                                                                      random_state=2022,\n","                                                                                      test_size=0.1)\n","\n","    ## 여기에 코드 작성(mask)\n","    train_masks, validation_masks,_ , _ =train_test_split(train_masks, train_label, random_state=2022, test_size=0.1)\n","    return train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks"]},{"cell_type":"markdown","id":"MebtEGjsERzf","metadata":{"id":"MebtEGjsERzf"},"source":["여기까지 구현한 부분을 하단의 preproc_test 함수의 세 번째 테스트로 확인해볼 \n","것이다. (60점)"]},{"cell_type":"markdown","id":"uKrLg_DKBJ-6","metadata":{"id":"uKrLg_DKBJ-6"},"source":["우리는 이렇게 나누어진 데이터들을 tensor의 형태로 변환해주어야 한다. data_to_tensor는 그러한 역할을 해주는 함수다.\n","\n","torch.tensor 함수를 활용해서 inputs, labels, masks 각각을 tensor로 변환해주는 함수를 구현해보자."]},{"cell_type":"code","execution_count":12,"id":"txWqnnYCT9dT","metadata":{"id":"txWqnnYCT9dT","executionInfo":{"status":"ok","timestamp":1660271921636,"user_tz":-540,"elapsed":299,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def data_to_tensor(inputs, labels, masks):\n","    # 입력받은 데이터를 텐서로 변환해주는 함수\n","    ## 여기에 코드 작성\n","    inputs_tensor = torch.tensor(inputs)\n","    labels_tensor = torch.tensor(labels)\n","    masks_tensor = torch.tensor(masks)\n","    \n","    return inputs_tensor, labels_tensor, masks_tensor"]},{"cell_type":"markdown","id":"iAwpViRKETw3","metadata":{"id":"iAwpViRKETw3"},"source":["여기까지 구현한 부분을 하단의 preproc_test 함수의 네 번째 테스트로 확인해볼 것이다. (80점)"]},{"cell_type":"markdown","id":"r0HUfeHmBUDE","metadata":{"id":"r0HUfeHmBUDE"},"source":["tensor로 변환한 데이터를 dataloader를 활용해서 batch 단위로 묶어줄 것이다.\n","\n","batch로 데이터를 묶어주기 전에, 데이터를 어떤 순서로 뽑을 것인지 적절한 Sampler를 설정해주어야 한다. 데이터가 학습을 위한 것인지, 검증을 위한 것인지에 따라서 알맞은 Sampler를 배정해주도록 하자."]},{"cell_type":"code","execution_count":13,"id":"CYvW5kkHUab-","metadata":{"id":"CYvW5kkHUab-","executionInfo":{"status":"ok","timestamp":1660271923910,"user_tz":-540,"elapsed":5,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["# 모든 DataLoader는 Sampler를 갖고 있다. Sampler는 데이터를 load 해올 때 데이터의 index를 컨트롤함으로써 어떤 데이터부터 가져올지 지정하는 기능을 한다.\n","# - SequentialSampler: 항상 같은 순서로, 순차적으로 데이터를 load 한다.\n","# - RandomSampler: 랜덤하게 데이터를 load 한다.\n","\n","def tensor_to_dataloader(inputs, labels, masks, mode):\n","    from torch.utils.data import RandomSampler, SequentialSampler\n","    \n","    batch_size=32\n","    data = TensorDataset(inputs, masks, labels)\n","    \n","    if mode == \"train\":\n","        # train 모드에서는 랜덤하게 데이터를 load해오는 sampler를 사용하자.\n","        # 대개 mini-batch 내부 구성이 다양할수록 전체 dataset(모집단)를 잘 대표하기 때문에 주로 RandomSampler를 사용한다. (https://hul980.tistory.com/28)\n","        ## 여기에 코드 작성\n","        sampler = RandomSampler(data)\n","    else:\n","        # test에는 순차적으로 데이터를 load하는 sampler을 지정하자.\n","        ## 여기에 코드 작성\n","        sampler = SequentialSampler(data)\n","    \n","    # DataLoader 함수를 활용해서 dataloader를 선언해보자.\n","    # batch_size는 batch_size로 설정하고, sampler는 위에서 지정한대로 설정해주자.\n","    ## 여기에 코드 작성\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","\n","    return dataloader"]},{"cell_type":"markdown","id":"OgafT913EYuI","metadata":{"id":"OgafT913EYuI"},"source":["여기까지 구현한 부분을 하단의 preproc_test 함수의 다섯 번째 테스트로 확인해볼 것이다. (100점)"]},{"cell_type":"markdown","id":"W75rhx9mBjT3","metadata":{"id":"W75rhx9mBjT3"},"source":["이제 전처리를 수행하는데 필요한 모든 함수들을 다 구현했다.\n","\n","구현한 함수들을 모아 preproc 함수를 최종적으로 만들었다."]},{"cell_type":"code","execution_count":14,"id":"R0BRFQIyPd2n","metadata":{"id":"R0BRFQIyPd2n","executionInfo":{"status":"ok","timestamp":1660271927062,"user_tz":-540,"elapsed":507,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def preproc(tokenizer, whole_dataset):\n","    # whole_dataset을 전처리하자.\n","    processed_dataset = data_processing(whole_dataset)\n","    \n","    # 전처리한 전체 데이터를 토큰화하자.\n","    tokenized_dataset, labels, attention_masks = tokenize_processed_data(tokenizer, processed_dataset)\n","\n","    # 토큰화한 전체 데이터를 train용과 test용으로 분리하자.\n","    train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks = split_into_train_test(tokenized_dataset, labels, attention_masks)\n","    # 토큰화한 train용 데이터를 train용과 validation용으로 분리하자.\n","    train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = split_into_train_validation(train_inputs, train_labels, train_masks)\n","\n","    # train용, validation용, test용 데이터 각각을 텐서로 변환하자.\n","    train_inputs, train_labels, train_masks = data_to_tensor(train_inputs, train_labels, train_masks)\n","    validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_inputs, validation_labels, validation_masks)\n","    test_inputs, test_labels, test_masks = data_to_tensor(test_inputs, test_labels, test_masks)\n","\n","    # train용, validation용, test용 텐서를 dataloader로 변환하자. \n","    train_dataloader = tensor_to_dataloader(train_inputs, train_labels, train_masks, \"train\")\n","    validation_dataloader = tensor_to_dataloader(validation_inputs, validation_labels, validation_masks, \"validation\")\n","    test_dataloader = tensor_to_dataloader(test_inputs, test_labels, test_masks, \"test\")\n","\n","    return train_dataloader, validation_dataloader, test_dataloader"]},{"cell_type":"markdown","id":"Z0d0FcgnDUm-","metadata":{"id":"Z0d0FcgnDUm-"},"source":["함수들이 잘 적절히 잘 만들어졌는지 preproc_test 함수를 통해 측정해보자.\n","\n","5개의 테스트로 구성되어 있으며, 각 테스트는 20점이다.\n","\n","첫 번째 테스트는 별도의 함수는 존재하지 않는다."]},{"cell_type":"code","execution_count":15,"id":"6vJd_A8dQori","metadata":{"id":"6vJd_A8dQori","executionInfo":{"status":"ok","timestamp":1660271930427,"user_tz":-540,"elapsed":451,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["with open(\"/content/gdrive/MyDrive/NLP/data.pickle\", \"rb\") as fr:\n","    data = pickle.load(fr)"]},{"cell_type":"code","execution_count":16,"id":"unBaK3EVs4Z4","metadata":{"id":"unBaK3EVs4Z4","executionInfo":{"status":"ok","timestamp":1660271932049,"user_tz":-540,"elapsed":394,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def test2(tokenized_data): ## preproc_test의 두 번째 테스트\n","  return (tokenized_data[2022] == data[0]).all()"]},{"cell_type":"code","execution_count":17,"id":"7hduBFcUA02J","metadata":{"id":"7hduBFcUA02J","executionInfo":{"status":"ok","timestamp":1660271933379,"user_tz":-540,"elapsed":3,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def test3(train_inputs, validation_inputs, test_masks): ## preproc_test의 세 번째 테스트\n","    if len(train_inputs) != 162000 or len(validation_inputs) != 18000 or len(test_masks) != 20000:\n","      return False\n","    return (train_inputs[2022] == data[1]).all()"]},{"cell_type":"code","execution_count":18,"id":"q2N_mPnMA4lJ","metadata":{"id":"q2N_mPnMA4lJ","executionInfo":{"status":"ok","timestamp":1660271934787,"user_tz":-540,"elapsed":292,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def test4(train_inputs): ## preproc_test의 네 번째 테스트\n","    \n","    return torch.equal(train_inputs[12345], data[2])"]},{"cell_type":"code","execution_count":19,"id":"d4yqouLBA7TN","metadata":{"id":"d4yqouLBA7TN","executionInfo":{"status":"ok","timestamp":1660271936658,"user_tz":-540,"elapsed":309,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def test5(train_dataloader): ## preproc_test의 다섯 번째 테스트\n","    \n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","          \n","          if step < 1234:\n","            continue\n","          if step > 1234:\n","            break\n","\n","          b_input_ids, b_input_mask, b_labels = batch\n","\n","    return torch.equal(b_input_ids[5], data[3])\n","        "]},{"cell_type":"code","execution_count":20,"id":"sUQ2c1HyA-Pc","metadata":{"id":"sUQ2c1HyA-Pc","executionInfo":{"status":"ok","timestamp":1660271940048,"user_tz":-540,"elapsed":295,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def preproc_test(tokenizer, whole_dataset):\n","\n","    print(\"================={}번째 테스트 시작===================\".format(1))\n","    # whole_dataset을 전처리하자.\n","    try:\n","      processed_dataset = data_processing(whole_dataset)\n","    except:\n","      print(traceback.format_exc())\n","      return 0\n","    print(\"================={}번째 테스트 성공===================\\n\".format(1))\n","\n","\n","    print(\"================={}번째 테스트 시작===================\".format(2))\n","    # 전처리한 전체 데이터를 토큰화하자.\n","    try:\n","      tokenized_dataset, labels, attention_masks = tokenize_processed_data(tokenizer, processed_dataset)\n","    except:\n","      print(traceback.format_exc())\n","      return 20\n","    if not test2(tokenized_dataset):\n","      return 20\n","    print(\"================={}번째 테스트 성공===================\\n\".format(2))\n","\n","\n","    print(\"================={}번째 테스트 시작===================\".format(3))\n","    # 토큰화한 전체 데이터를 train용과 test용으로 분리하자.\n","    try:\n","      train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks = split_into_train_test(tokenized_dataset, labels, attention_masks)\n","      # 토큰화한 train용 데이터를 train용과 validation용으로 분리하자.\n","      train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = split_into_train_validation(train_inputs, train_labels, train_masks)\n","    except:\n","      print(traceback.format_exc())\n","      return 40\n","    if not test3(train_inputs, validation_inputs, test_masks):\n","      return 40\n","    print(\"================={}번째 테스트 성공===================\\n\".format(3))\n","\n","\n","    print(\"================={}번째 테스트 시작===================\".format(4))\n","    # train용, validation용, test용 데이터 각각을 텐서로 변환하자.\n","    try:\n","      train_inputs, train_labels, train_masks = data_to_tensor(train_inputs, train_labels, train_masks)\n","      validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_inputs, validation_labels, validation_masks)\n","      test_inputs, test_labels, test_masks = data_to_tensor(test_inputs, test_labels, test_masks)\n","    except:\n","      print(traceback.format_exc())\n","      return 60\n","    if not test4(train_inputs):\n","      return 60\n","    print(\"================={}번째 테스트 성공===================\\n\".format(4))\n","\n","\n","    print(\"================={}번째 테스트 시작===================\".format(5))\n","    # train용, validation용, test용 텐서를 dataloader로 변환하자. \n","    try:\n","      train_dataloader = tensor_to_dataloader(train_inputs, train_labels, train_masks, \"train\")\n","      validation_dataloader = tensor_to_dataloader(validation_inputs, validation_labels, validation_masks, \"validation\")\n","      test_dataloader = tensor_to_dataloader(test_inputs, test_labels, test_masks, \"test\")\n","    except:\n","      print(traceback.format_exc())\n","      return 80\n","    if not test5(train_dataloader):\n","      return 80\n","    print(\"================={}번째 테스트 성공===================\\n\".format(5))\n","\n","\n","    return 100"]},{"cell_type":"code","execution_count":21,"id":"7U6SEQwTcZrE","metadata":{"id":"7U6SEQwTcZrE","executionInfo":{"status":"ok","timestamp":1660271944029,"user_tz":-540,"elapsed":292,"user":{"displayName":"승희송승","userId":"13532987981801919518"}}},"outputs":[],"source":["def main():\n","    %cd /content/gdrive/MyDrive/NLP\n","    from tokenization import KoBertTokenizer\n","\n","    # 전체 데이터를 불러오자.\n","    whole_dataset = pd.read_csv('/content/gdrive/MyDrive/NLP/ratings.txt', delimiter=\"\\t\")\n","    \n","    # KoBERTTokenizer를 불러오자.\n","    tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\")\n","  \n","    \n","    score = preproc_test(tokenizer, whole_dataset)\n","    print(\"현재 점수 : {}/100점\".format(score))\n","        "]},{"cell_type":"markdown","id":"0k1-rDdeIxJf","metadata":{"id":"0k1-rDdeIxJf"},"source":["아래 쉘을 실행하면 테스트의 점수를 알 수 있다.\n","\n","***100점이 되어야 다음 섹터로 넘어갈 수 있다.***"]},{"cell_type":"code","execution_count":22,"id":"AOloXaFbXo-X","metadata":{"id":"AOloXaFbXo-X","colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["072d187c72514487874866e9ba30c7cb","bc26b65aad054afb8ef63485e593b9d3","781419edb9f94dafb59d20a646e2c265","22ef2bf58b694237b93b6076a7991982","386d413cb9bd4b1387eb197c89fa5fb3","84360acd60f448e18c0323ef2e6a20c6","762a594d443143809db37bc4a4d6ca8d","571c0b0e9c574dc099b17b11e0b25b6e","9c837446d28940169bbf969f273493b6","276606d3628e4d3d854c8c16223e6c9f","5cdcb1cb0dfe410f9babd42139b8bfdc","7d934d85af694ce887aea26892ecef65","4ada17ecfcec40a4b8539c6d338b0a62","05d284f50ddc4d80918ae98f650902e1","fc1a77ccf84f4b67a6fd760e4d42f6ce","f7cb30979da3453b89312c0b89071ab5","5ab534b627ba4de49d4ab0d253a74284","8904a19762804abf880e41abe0b935b5","3ad44f7b3f6f4398900e094707c42bce","4d134fa95d514f61b0235a5cc9f8a32e","bc29823e77c54b459196dfd736d98c63","531e7c6afaeb43c2bc7306e6af62bb79"]},"executionInfo":{"status":"ok","timestamp":1660271991029,"user_tz":-540,"elapsed":42635,"user":{"displayName":"승희송승","userId":"13532987981801919518"}},"outputId":"09a517f1-5549-4c8e-b02a-fbc0b20b4224"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/NLP\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/371k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072d187c72514487874866e9ba30c7cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d934d85af694ce887aea26892ecef65"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=================1번째 테스트 시작===================\n","=================1번째 테스트 성공===================\n","\n","=================2번째 테스트 시작===================\n","=================2번째 테스트 성공===================\n","\n","=================3번째 테스트 시작===================\n","length of whole_data : 200000\n","length of train_data : 180000\n","=================3번째 테스트 성공===================\n","\n","=================4번째 테스트 시작===================\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["=================4번째 테스트 성공===================\n","\n","=================5번째 테스트 시작===================\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▍       | 1235/5063 [00:00<00:01, 3223.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=================5번째 테스트 성공===================\n","\n","현재 점수 : 100/100점\n"]}],"source":["if __name__ == '__main__':\n","\n","    # 시드 고정\n","    seed_val = 2022\n","    np.random.seed(seed_val)\n","    torch.manual_seed(seed_val)\n","    torch.cuda.manual_seed_all(seed_val)\n","\n","    main()"]},{"cell_type":"code","execution_count":null,"id":"5-OfuvBSaR_N","metadata":{"id":"5-OfuvBSaR_N"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Preproc.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"072d187c72514487874866e9ba30c7cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc26b65aad054afb8ef63485e593b9d3","IPY_MODEL_781419edb9f94dafb59d20a646e2c265","IPY_MODEL_22ef2bf58b694237b93b6076a7991982"],"layout":"IPY_MODEL_386d413cb9bd4b1387eb197c89fa5fb3"}},"bc26b65aad054afb8ef63485e593b9d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84360acd60f448e18c0323ef2e6a20c6","placeholder":"​","style":"IPY_MODEL_762a594d443143809db37bc4a4d6ca8d","value":"Downloading: 100%"}},"781419edb9f94dafb59d20a646e2c265":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_571c0b0e9c574dc099b17b11e0b25b6e","max":371391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c837446d28940169bbf969f273493b6","value":371391}},"22ef2bf58b694237b93b6076a7991982":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_276606d3628e4d3d854c8c16223e6c9f","placeholder":"​","style":"IPY_MODEL_5cdcb1cb0dfe410f9babd42139b8bfdc","value":" 371k/371k [00:00&lt;00:00, 6.83MB/s]"}},"386d413cb9bd4b1387eb197c89fa5fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84360acd60f448e18c0323ef2e6a20c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"762a594d443143809db37bc4a4d6ca8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"571c0b0e9c574dc099b17b11e0b25b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c837446d28940169bbf969f273493b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"276606d3628e4d3d854c8c16223e6c9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cdcb1cb0dfe410f9babd42139b8bfdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d934d85af694ce887aea26892ecef65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ada17ecfcec40a4b8539c6d338b0a62","IPY_MODEL_05d284f50ddc4d80918ae98f650902e1","IPY_MODEL_fc1a77ccf84f4b67a6fd760e4d42f6ce"],"layout":"IPY_MODEL_f7cb30979da3453b89312c0b89071ab5"}},"4ada17ecfcec40a4b8539c6d338b0a62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab534b627ba4de49d4ab0d253a74284","placeholder":"​","style":"IPY_MODEL_8904a19762804abf880e41abe0b935b5","value":"Downloading: 100%"}},"05d284f50ddc4d80918ae98f650902e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ad44f7b3f6f4398900e094707c42bce","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d134fa95d514f61b0235a5cc9f8a32e","value":77779}},"fc1a77ccf84f4b67a6fd760e4d42f6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc29823e77c54b459196dfd736d98c63","placeholder":"​","style":"IPY_MODEL_531e7c6afaeb43c2bc7306e6af62bb79","value":" 77.8k/77.8k [00:00&lt;00:00, 2.18MB/s]"}},"f7cb30979da3453b89312c0b89071ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab534b627ba4de49d4ab0d253a74284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8904a19762804abf880e41abe0b935b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ad44f7b3f6f4398900e094707c42bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d134fa95d514f61b0235a5cc9f8a32e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc29823e77c54b459196dfd736d98c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"531e7c6afaeb43c2bc7306e6af62bb79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}